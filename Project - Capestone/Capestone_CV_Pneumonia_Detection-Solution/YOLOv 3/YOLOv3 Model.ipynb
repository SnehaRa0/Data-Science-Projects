{"cells":[{"metadata":{"trusted":true,"_uuid":"ce28f29df7b9f64725998f8133be50068c53cb69"},"cell_type":"code","source":"import math\nimport os\nimport shutil\nimport sys\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport pydicom\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4b33affdc049734daa58852c4ed06e37c344063"},"cell_type":"code","source":"random_stat = 5675\nnp.random.seed(random_stat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97d22b2e1c828e655e7df04474169cd0d7a5a031"},"cell_type":"markdown","source":"## 1. Clone and Build YOLOv3"},{"metadata":{"trusted":true,"_uuid":"558964006de8b4e454d76c91a5d0a605e397a93d"},"cell_type":"code","source":"!git clone https://github.com/pjreddie/darknet.git\n\n# Build gpu version darknet\n!cd darknet && sed '1 s/^.*$/GPU=1/; 2 s/^.*$/CUDNN=1/' -i Makefile\n\n# -j <The # of cpu cores to use>. Chang 999 to fit your environment. Actually i used '-j 50'.\n!cd darknet && make -j 999 -s\n!cp darknet/darknet darknet_gpu","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f77f087a15c73fae7a710fd560244b8f7884197"},"cell_type":"markdown","source":"## 2. Data Preparation for YOLOv3\n"},{"metadata":{"trusted":true,"_uuid":"55f5d67ac085afcc445db23227ba60748eb269fa"},"cell_type":"code","source":"DATA_DIR = \"../input\"\n\ntrain_dcm_dir = os.path.join(DATA_DIR, \"stage_2_train_images\")\ntest_dcm_dir = os.path.join(DATA_DIR, \"stage_2_test_images\")\n\nimg_dir = os.path.join(os.getcwd(), \"images\")  # .jpg\nlabel_dir = os.path.join(os.getcwd(), \"labels\")  # .txt\nmetadata_dir = os.path.join(os.getcwd(), \"metadata\") # .txt\n\n# YOLOv3 config file directory\ncfg_dir = os.path.join(os.getcwd(), \"cfg\")\n# YOLOv3 training checkpoints will be saved here\nbackup_dir = os.path.join(os.getcwd(), \"backup\")\n\nfor directory in [img_dir, label_dir, metadata_dir, cfg_dir, backup_dir]:\n    if os.path.isdir(directory):\n        continue\n    os.mkdir(directory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e242b29961c22433703e442a84572783b9459de9"},"cell_type":"code","source":"annots = pd.read_csv(os.path.join(DATA_DIR, \"stage_2_train_labels.csv\"))\nannots.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b26d929bb119deca558ac983a5ce4e95fe9b7cc"},"cell_type":"markdown","source":"### 2.2. Generate images and labels for training YOLOv3\n"},{"metadata":{"trusted":true,"_uuid":"5204d3b142e17927c06e9e992dd4e4f4a3d0c8ab"},"cell_type":"code","source":"def save_img_from_dcm(dcm_dir, img_dir, patient_id):\n    img_fp = os.path.join(img_dir, \"{}.jpg\".format(patient_id))\n    if os.path.exists(img_fp):\n        return\n    dcm_fp = os.path.join(dcm_dir, \"{}.dcm\".format(patient_id))\n    img_1ch = pydicom.read_file(dcm_fp).pixel_array\n    img_3ch = np.stack([img_1ch]*3, -1)\n\n    img_fp = os.path.join(img_dir, \"{}.jpg\".format(patient_id))\n    cv2.imwrite(img_fp, img_3ch)\n    \ndef save_label_from_dcm(label_dir, patient_id, row=None):\n    # rsna defualt image size\n    img_size = 1024\n    label_fp = os.path.join(label_dir, \"{}.txt\".format(patient_id))\n    \n    f = open(label_fp, \"a\")\n    if row is None:\n        f.close()\n        return\n\n    top_left_x = row[1]\n    top_left_y = row[2]\n    w = row[3]\n    h = row[4]\n    \n    # 'r' means relative. 'c' means center.\n    rx = top_left_x/img_size\n    ry = top_left_y/img_size\n    rw = w/img_size\n    rh = h/img_size\n    rcx = rx+rw/2\n    rcy = ry+rh/2\n    \n    line = \"{} {} {} {} {}\\n\".format(0, rcx, rcy, rw, rh)\n    \n    f.write(line)\n    f.close()\n        \ndef save_yolov3_data_from_rsna(dcm_dir, img_dir, label_dir, annots):\n    for row in tqdm(annots.values):\n        patient_id = row[0]\n\n        img_fp = os.path.join(img_dir, \"{}.jpg\".format(patient_id))\n        if os.path.exists(img_fp):\n            save_label_from_dcm(label_dir, patient_id, row)\n            continue\n\n        target = row[5]\n        # Since kaggle kernel have samll volume (5GB ?), I didn't contain files with no bbox here.\n        if target == 0:\n            continue\n        save_label_from_dcm(label_dir, patient_id, row)\n        save_img_from_dcm(dcm_dir, img_dir, patient_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e907f30b11bf6956884061138d615bee60c2a15"},"cell_type":"code","source":"save_yolov3_data_from_rsna(train_dcm_dir, img_dir, label_dir, annots)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42551c1e11208ee88f9b93bea40c23dcad295b8a"},"cell_type":"markdown","source":"###  Generate train/val file path list (.txt)\n* We should give the list of image paths to YOLO. two seperate list textfiles for training images and validation images."},{"metadata":{"trusted":true,"_uuid":"d62f98b287e73a66c234c4c9f9e41503fc0d4bca"},"cell_type":"code","source":"def write_train_list(metadata_dir, img_dir, name, series):\n    list_fp = os.path.join(metadata_dir, name)\n    with open(list_fp, \"w\") as f:\n        for patient_id in series:\n            line = \"{}\\n\".format(os.path.join(img_dir, \"{}.jpg\".format(patient_id)))\n            f.write(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c3982b42711fe4a20600b90ed3d123384da7096"},"cell_type":"code","source":"# Following lines do not contain data with no bbox\npatient_id_series = annots[annots.Target == 1].patientId.drop_duplicates()\n\ntr_series, val_series = train_test_split(patient_id_series, test_size=0.1, random_state=random_stat)\nprint(\"The # of train set: {}, The # of validation set: {}\".format(tr_series.shape[0], val_series.shape[0]))\n\n# train image path list\nwrite_train_list(metadata_dir, img_dir, \"tr_list.txt\", tr_series)\n# validation image path list\nwrite_train_list(metadata_dir, img_dir, \"val_list.txt\", val_series)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"482fc4b015279312504c910b6c910a5d58960159"},"cell_type":"markdown","source":"### Create test image and labels for YOLOv3"},{"metadata":{"trusted":true,"_uuid":"7394207f5f23778aee12d5f4dadae632b340ce62"},"cell_type":"code","source":"def save_yolov3_test_data(test_dcm_dir, img_dir, metadata_dir, name, series):\n    list_fp = os.path.join(metadata_dir, name)\n    with open(list_fp, \"w\") as f:\n        for patient_id in series:\n            save_img_from_dcm(test_dcm_dir, img_dir, patient_id)\n            line = \"{}\\n\".format(os.path.join(img_dir, \"{}.jpg\".format(patient_id)))\n            f.write(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e99463093b202e2aabfcd3979701b7e47ba91c3e"},"cell_type":"code","source":"test_dcm_fps = list(set(glob.glob(os.path.join(test_dcm_dir, '*.dcm'))))\ntest_dcm_fps = pd.Series(test_dcm_fps).apply(lambda dcm_fp: dcm_fp.strip().split(\"/\")[-1].replace(\".dcm\",\"\"))\n\nsave_yolov3_test_data(test_dcm_dir, img_dir, metadata_dir, \"te_list.txt\", test_dcm_fps)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42c007da9fd2009310dcf697bca943c4dd7a33f7"},"cell_type":"markdown","source":"### Plot a sample test Image"},{"metadata":{"trusted":true,"_uuid":"f057a0fc9938308f69a5d402cf51ba340af592c0"},"cell_type":"code","source":"ex_patient_id = test_dcm_fps[0]\nex_img_path = os.path.join(img_dir, \"{}.jpg\".format(ex_patient_id))\n\nplt.imshow(cv2.imread(ex_img_path))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6415f6efcae6fca1812cb402af668428d2918e46"},"cell_type":"markdown","source":"### Download Pre-trained Model\nFor training, we would download the pre-trained model weights(darknet53.conv.74) using following wget command. "},{"metadata":{"trusted":true,"_uuid":"ec2d5fbdfe6f3eebd553495d10f9adcdae29f16f"},"cell_type":"code","source":"!wget -q https://pjreddie.com/media/files/darknet53.conv.74","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f03592ee228f9ae16edac192071955d01233a147"},"cell_type":"markdown","source":"* ## 4. Training YOLOv3"},{"metadata":{"trusted":true,"_uuid":"0be53a581ab12776c1c276f72acbf08b2db16d77"},"cell_type":"code","source":"!./darknet_gpu detector train cfg/rsna.data cfg/rsna_yolov3.cfg_train darknet53.conv.74 -i 0 | tee train_log.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Evaluating the performance of the model\nWe are evaluating the models based on the below metrics\n\nAccuracy\nPrecision\nRecall\nF1 score\nMean IoU "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on test images, write out sample submission\ndef predict_val(image_fps, filepath='val_sample.csv', min_conf=0.95):\n    # assume square image\n    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n    #resize_factor = ORIG_SIZE\n    with open(filepath, 'w') as file:\n        file.write(\"patientId,score,x1,y1,width,height\\n\")\n\n        for image_id in tqdm(image_fps):\n            ds = pydicom.read_file(image_id)\n            image = ds.pixel_array\n            # If grayscale. Convert to RGB for consistency.\n            if len(image.shape) != 3 or image.shape[2] != 3:\n                image = np.stack((image,) * 3, -1)\n            image, window, scale, padding, crop = utils.resize_image(\n                image,\n                min_dim=config.IMAGE_MIN_DIM,\n                min_scale=config.IMAGE_MIN_SCALE,\n                max_dim=config.IMAGE_MAX_DIM,\n                mode=config.IMAGE_RESIZE_MODE)\n\n            patient_id = os.path.splitext(os.path.basename(image_id))[0]\n\n            results = model.detect([image])\n            r = results[0]\n\n            assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n            if len(r['rois']) != 0:\n              num_instances = len(r['rois'])\n              score = []  \n              for i in range(num_instances):\n                    score.append(r['scores'][i])\n                    \n                    if r['scores'][i] >= min_conf:\n                      out_str = \"\"\n                      out_str += patient_id\n                      out_str += \",\"\n                      out_str += \"\"\n                      out_str += str(round(r['scores'][i], 2))\n                      out_str += \",\"\n                      x1 = r['rois'][i][1]\n                      out_str += \"\"\n                      out_str += str(x1*resize_factor)\n                      out_str += \",\"\n                      y1 = r['rois'][i][0]\n                      out_str += \"\"\n                      out_str += str(y1*resize_factor)\n                      out_str += \",\"\n                      width = r['rois'][i][3] - x1\n                      out_str += \"\"\n                      out_str += str(width*resize_factor)\n                      out_str += \",\"\n                      height = r['rois'][i][2] - y1\n                      out_str += \"\"\n                      out_str += str(height*resize_factor)\n                      out_str += \",\"\n                      file.write(out_str+\"\\n\")\n                    \n              if max(score) < min_conf:\n                      out_str = \"\"\n                      out_str += patient_id\n                      out_str += \",\"\n                      file.write(out_str+\"\\n\")  \n            \n            else:\n                out_str = \"\"\n                out_str += patient_id\n                out_str += \",\"\n                file.write(out_str+\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_sample_fp = os.path.join(ROOT_DIR, 'val_sample.csv')\npredict_val(image_fps_val, filepath=val_sample_fp)\nprint(val_sample_fp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = [\"patientId\",\"score_pred\",\"x_pred\",\"y_pred\",\"width_pred\",\"height_pred\"]\nval_pred = pd.read_csv(val_sample_fp, delimiter = \",\", names = col_names)\nval_pred.drop(val_pred.index[0], inplace = True)\nval_pred.sort_values(by = \"patientId\", inplace = True)\nval_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_list = set(val_pred['patientId'])\nval_actuals = anns[anns['patientId'].isin(validation_list)]\nval_actuals.sort_values(by = \"patientId\", inplace = True)\nlen(validation_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_compare = pd.merge(val_pred, val_actuals, how='inner', on= 'patientId', left_on=None, right_on=None,\n         left_index=False, right_index=False, sort=True,\n         suffixes=('_x', '_y'), copy=True, indicator=False,\n         validate=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_compare.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report \nfrom sklearn.metrics import confusion_matrix ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_compare['score_pred'] = val_compare['score_pred'].astype(float)\nval_compare['x_pred'] = val_compare['x_pred'].astype(float)\nval_compare['y_pred'] = val_compare['y_pred'].astype(float)\nval_compare['height_pred'] = val_compare['height_pred'].astype(float)\nval_compare['width_pred'] = val_compare['width_pred'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = confusion_matrix(val_compare['Target'], val_compare['score_pred'].round())  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining function to find IoU scores\ndef IOU(x,y,width,height,x_pred,y_pred,width_pred,height_pred):\n    w_intersection = min(x + width, x_pred + width_pred) - max(x, x_pred)\n    h_intersection = min(y + height, y_pred + height_pred) - max(y, y_pred)\n    if w_intersection <= 0 or h_intersection <= 0: # No overlap\n        return 0\n    I = w_intersection * h_intersection\n    U = width * height + width_pred * height_pred - I # Union = Total Area - I\n    return I / U","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_compare['IoU'] = val_compare.apply(lambda x: IOU(x['x'],x['y'],x['width'],x['height'],x['x_pred'],x['y_pred'],x['width_pred'],x['height_pred']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluation Metrics\")\nprint(classification_report(val_compare['Target'], val_compare['score_pred'].round()))\nprint(\"confusion matrix\")\nprint(results)\nprint(\"IoU Scores\")\nval_compare.groupby('Target')[\"IoU\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}